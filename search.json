[
  {
    "objectID": "posts/07-stepwise_datasplitting_simulation/index.html",
    "href": "posts/07-stepwise_datasplitting_simulation/index.html",
    "title": "Model Fitting and Validation",
    "section": "",
    "text": "This is Part Two of an \\(N\\)1 part series on model fitting and validation. Part One can be found here."
  },
  {
    "objectID": "posts/07-stepwise_datasplitting_simulation/index.html#prerequisites-and-data-cleaning",
    "href": "posts/07-stepwise_datasplitting_simulation/index.html#prerequisites-and-data-cleaning",
    "title": "Model Fitting and Validation",
    "section": "Prerequisites and data cleaning",
    "text": "Prerequisites and data cleaning\nThe lung dataset is from the {survival} package (Therneau 2024), and I will use {data.table} (Barrett et al. 2024) as I like the syntax and it’s fast.\n\nTherneau, Terry M. 2024. A Package for Survival Analysis in r. https://CRAN.R-project.org/package=survival.\n\nBarrett, Tyson, Matt Dowle, Arun Srinivasan, Jan Gorecki, Michael Chirico, Toby Hocking, and Benjamin Schwendinger. 2024. Data.table: Extension of ‘Data.frame‘. https://CRAN.R-project.org/package=data.table.\n\nlibrary(survival)\nlibrary(broom) # for 'tidy'\nlibrary(data.table)\noptions(datatable.print.nrows = 20) # set max # rows before truncating (default = 100)\nlibrary(ggplot2)\nlung &lt;- as.data.table(lung)\nlung\n\n      inst  time status   age   sex ph.ecog ph.karno pat.karno meal.cal wt.loss\n     &lt;num&gt; &lt;num&gt;  &lt;num&gt; &lt;num&gt; &lt;num&gt;   &lt;num&gt;    &lt;num&gt;     &lt;num&gt;    &lt;num&gt;   &lt;num&gt;\n  1:     3   306      2    74     1       1       90       100     1175      NA\n  2:     3   455      2    68     1       0       90        90     1225      15\n  3:     3  1010      1    56     1       0       90        90       NA      15\n  4:     5   210      2    57     1       1       90        60     1150      11\n  5:     1   883      2    60     1       0      100        90       NA       0\n ---                                                                           \n224:     1   188      1    77     1       1       80        60       NA       3\n225:    13   191      1    39     1       0       90        90     2350      -5\n226:    32   105      1    75     2       2       60        70     1025       5\n227:     6   174      1    66     1       1       90       100     1075       1\n228:    22   177      1    58     2       1       80        90     1060       0\n\n\nThe lung dataset has status encoded in a non-standard way (as 1 for censored and 2 for dead). I will change this to 0 and 1 respectively. I will also ensure the data contains no missingness by using na.omit().\n\n#recode 'status' as 1 if event and 0 if censored\nlung_recode &lt;- copy(lung)[, status := as.integer(status == 2)]\n\n# remove NA's (st 'ampute' works)\nlung_complete &lt;- na.omit(lung_recode)\n\nlung_complete[, `:=`(sex = as.factor(sex), ph.ecog = as.factor(ph.ecog))]\n\nlung_complete\n\n      inst  time status   age    sex ph.ecog ph.karno pat.karno meal.cal\n     &lt;num&gt; &lt;num&gt;  &lt;int&gt; &lt;num&gt; &lt;fctr&gt;  &lt;fctr&gt;    &lt;num&gt;     &lt;num&gt;    &lt;num&gt;\n  1:     3   455      1    68      1       0       90        90     1225\n  2:     5   210      1    57      1       1       90        60     1150\n  3:    12  1022      0    74      1       1       50        80      513\n  4:     7   310      1    68      2       2       70        60      384\n  5:    11   361      1    71      2       2       60        80      538\n ---                                                                    \n163:    11   203      0    71      2       1       80        90     1025\n164:    13   191      0    39      1       0       90        90     2350\n165:    32   105      0    75      2       2       60        70     1025\n166:     6   174      0    66      1       1       90       100     1075\n167:    22   177      0    58      2       1       80        90     1060\n     wt.loss\n       &lt;num&gt;\n  1:      15\n  2:      11\n  3:       0\n  4:      10\n  5:       1\n ---        \n163:       0\n164:      -5\n165:       5\n166:       1\n167:       0"
  },
  {
    "objectID": "posts/07-stepwise_datasplitting_simulation/index.html#the-model-factors",
    "href": "posts/07-stepwise_datasplitting_simulation/index.html#the-model-factors",
    "title": "Model Fitting and Validation",
    "section": "The model factors",
    "text": "The model factors\nFirst, let’s look at the proportion that each factor has been chosen to be in the 100 models.\n\n\n\n\nwhich_variables &lt;- models[, unique(term)]\n\nproportion_variables &lt;- rbindlist(\n      lapply(1:length(which_variables), \n             function(i) {\n              prop_tmp &lt;- nrow(models[term == which_variables[i]]) / n_sim\n              data.table(which_variables[i], prop_tmp)\n                    }\n             )\n      )\n\n# categorical factors in each model are present in the `models` dataset multiple times\n# e.g. 'ph.ecog1', 'ph.ecog2', etc.\n# create a \"expl_factor\" group by removing trailing digits\nproportion_variables[\n  , expl_factor := sub(\"[0-9]+$\", \"\", V1)\n]\n\n# collapse by the explanatory factor\ngrouped_proportions &lt;- proportion_variables[\n  , .(prop = unique(prop_tmp)),\n  by = expl_factor\n]\n\ngrouped_proportions[order(prop, decreasing = TRUE)]\n\n\nListing 3: Obtaining the proportion that each factor is chosen to be in the models.\n\n\n\n\n   expl_factor  prop\n        &lt;char&gt; &lt;num&gt;\n1:     ph.ecog  0.94\n2:         sex  0.91\n3:        inst  0.72\n4:     wt.loss  0.68\n5:    ph.karno  0.64\n6:   pat.karno  0.30\n7:         age  0.22\n8:    meal.cal  0.04\n\n\nNow I’ll consider each model and the factors obtained using the stepwise procedure. First – in Listing 4 – I’ll create a terms_string variable that gives a string containing all the terms in each of the 100 models. Then – in Listing 5 – I’ll group these models together to see how many different combination of factors have been chosen from the 100 stepwise selection procedures.\n\n\n\n\nmodel_variables &lt;- models[, .(\n  terms_string = paste(\n    unique(sub(\"[0-9]+$\", \"\", term)),\n    collapse = \", \"\n  )\n), by = .id]\n\nmodel_variables\n\n\nListing 4: Creating string of all the factors in each of the models.\n\n\n\n\n       .id                                     terms_string\n     &lt;int&gt;                                           &lt;char&gt;\n  1:     1                     inst, sex, ph.ecog, ph.karno\n  2:     2            inst, sex, ph.ecog, ph.karno, wt.loss\n  3:     3                 sex, ph.ecog, pat.karno, wt.loss\n  4:     4       sex, ph.ecog, ph.karno, pat.karno, wt.loss\n  5:     5                inst, age, sex, ph.ecog, ph.karno\n ---                                                       \n 96:    96             age, sex, ph.ecog, ph.karno, wt.loss\n 97:    97            inst, sex, ph.ecog, ph.karno, wt.loss\n 98:    98 inst, sex, ph.ecog, ph.karno, pat.karno, wt.loss\n 99:    99                      age, sex, ph.ecog, ph.karno\n100:   100                           sex, ph.ecog, ph.karno\n\n\nGrouping these models together gives the follow:\n\n\n\n\nproportion_model_variables &lt;- model_variables[\n      , .(prop = nrow(.SD) / nrow(model_variables))\n      , by = terms_string]\n\n#proportion_model_variables\nproportion_model_variables[order(prop, decreasing = TRUE)]\n\n\nListing 5: Grouping models together to show the number of different models obtained from using stepwise selection.\n\n\n\n\n                                        terms_string  prop\n                                              &lt;char&gt; &lt;num&gt;\n 1:            inst, sex, ph.ecog, ph.karno, wt.loss  0.14\n 2:                      inst, sex, ph.ecog, wt.loss  0.13\n 3: inst, sex, ph.ecog, ph.karno, pat.karno, wt.loss  0.11\n 4:                     inst, sex, ph.ecog, ph.karno  0.06\n 5:                inst, age, sex, ph.ecog, ph.karno  0.04\n---                                                       \n30:           inst, sex, ph.ecog, pat.karno, wt.loss  0.01\n31:                                        pat.karno  0.01\n32:                     inst, sex, ph.ecog, meal.cal  0.01\n33:  inst, sex, ph.ecog, ph.karno, meal.cal, wt.loss  0.01\n34:             age, sex, ph.ecog, ph.karno, wt.loss  0.01\n\n\nThat is, from 100 simulations of splitting the data into a training and test set, I’ve obtained 34 different models!\n\nThe factor coefficients\nOK – let’s look at the variability of the coefficient estimates for each factor. First, I’ll get summary statistics for each factor coefficient. A box-plot showing this variability is given in Figure 1, and the kernel densities of the estimates are shown in Figure 2.\n\n# Remove any rows that have NA in the estimate\nmodels_clean &lt;- subset(models, !is.na(estimate))\n\nmodels_clean[, as.list(summary(estimate)), by = term]\n\n         term          Min.       1st Qu.        Median          Mean\n       &lt;char&gt;         &lt;num&gt;         &lt;num&gt;         &lt;num&gt;         &lt;num&gt;\n 1:      inst -0.0509354446 -0.0365704124 -0.0302755030 -0.0320112247\n 2:      sex2 -1.1315746564 -0.7029760419 -0.5881394025 -0.6093326104\n 3:  ph.ecog1  0.1420228124  0.5092835045  0.7024669149  0.7242113000\n 4:  ph.ecog2  0.8063634936  1.3599992736  1.7791183312  1.7739151854\n 5:  ph.ecog3  1.8659038585  2.5201583000  3.0779479537  3.0501194170\n 6:  ph.karno -0.0211069194  0.0252318873  0.0304998545  0.0305489979\n 7:   wt.loss -0.0292142915 -0.0210200718 -0.0186741004 -0.0187607396\n 8: pat.karno -0.0280318096 -0.0223547207 -0.0183404498 -0.0193037902\n 9:       age  0.0208960667  0.0220780244  0.0227820171  0.0242739341\n10:  meal.cal -0.0009556685 -0.0007011441 -0.0006010875 -0.0006590115\n          3rd Qu.          Max.\n            &lt;num&gt;         &lt;num&gt;\n 1: -0.0262214394 -0.0216371920\n 2: -0.5037040983 -0.3564017818\n 3:  0.9017954598  1.4072391610\n 4:  2.1107234044  2.8765227030\n 5:  3.5501307812  4.2490415152\n 6:  0.0372071507  0.0516899027\n 7: -0.0160832211 -0.0122667120\n 8: -0.0169197955 -0.0142537345\n 9:  0.0248300821  0.0391007125\n10: -0.0005589549 -0.0004782023\n\n\n\nggplot(models_clean, aes(x=term, y=estimate)) +\n  geom_boxplot() +\n  theme_minimal() +\n  theme(\n     axis.title = element_blank(),\n     # remove the grid lines\n     panel.grid.major = element_blank() ,\n     panel.grid.minor = element_blank() ,\n     # explicitly set the horizontal lines \n     panel.grid.major.y = element_line(linewidth = .1, color = \"grey\" )\n        )\n\n\n\n\n\n\n\nFigure 1: Box plots showing the variability in the factor coefficient estimates.\n\n\n\n\n\nWe can see from Figure 1 (and by referring back to Listing 3) that the factors that are chosen the most times have the largest varibility in their coefficient estimates.\n\nggplot(models_clean, aes(x = estimate)) +\n  geom_density(fill = \"grey\", alpha = 0.4) +\n  facet_wrap(~ term, scales = \"free\") +\n  labs(\n    title = \"Density Plot of Factor Coefficients\",\n    x = \"Coefficient Estimate\",\n    y = \"Density\"\n  ) +\n  theme_minimal() +\n  theme(\n     axis.text.y = element_blank(),\n     axis.title.y=element_blank(),\n     # remove the grid lines\n     panel.grid.major = element_blank() ,\n     panel.grid.minor = element_blank() ,\n     # explicitly set the horizontal lines \n     panel.grid.major.y = element_line(linewidth = .1, color = \"grey\" )\n  )\n\n\n\n\n\n\n\nFigure 2: Density plots of the estimates for each factor coefficient."
  },
  {
    "objectID": "posts/07-stepwise_datasplitting_simulation/index.html#the-c-index-on-the-test-sets",
    "href": "posts/07-stepwise_datasplitting_simulation/index.html#the-c-index-on-the-test-sets",
    "title": "Model Fitting and Validation",
    "section": "The C-Index on the test sets",
    "text": "The C-Index on the test sets\nFinally, let’s look at how the C-index varies for each training/test split and respective model. The code in Listing 6 gives the C-index values obtained from the 100 models, and the histogram is given in Figure 3.\n\n\n\n\nc_stats &lt;- models[, .(c_stats = unique(c)), by = .id]\nc_stats[order(c_stats, decreasing = TRUE)]\n\n\nListing 6: Code to output the C-index, in descending order.\n\n\n\n\n       .id   c_stats\n     &lt;int&gt;     &lt;num&gt;\n  1:     2 0.5389682\n  2:    66 0.5209644\n  3:    18 0.5016181\n  4:     7 0.4980198\n  5:    53 0.4910000\n ---                \n 96:    50 0.3403491\n 97:    58 0.3378525\n 98:    25 0.3326271\n 99:     6 0.3164300\n100:    52 0.2878486\n\n\n\nggplot(c_stats, aes(x = c_stats)) +\n        stat_bin(bins = 30) +\n        xlab(\"C-Index\") + ylab(\"\") +\n        theme_minimal() +\n        theme(\n           # remove the grid lines\n           panel.grid.major = element_blank() ,\n           panel.grid.minor = element_blank() ,\n           # explicitly set the horizontal lines \n           panel.grid.major.y = element_line(linewidth = .1, color = \"grey\" )\n        )\n\n\n\n\n\n\n\nFigure 3: Histogram of the C-index values obtained on the test sets of the models."
  },
  {
    "objectID": "posts/04-highcharter_bar/index.html",
    "href": "posts/04-highcharter_bar/index.html",
    "title": "A Bidirectional Bar Chart using Highcharter",
    "section": "",
    "text": "This is just a quick post, as a follow on to my previous highcharter posts (one and two).\nI wanted a bar chart that looks like Figure 1, which was made using Flourish.\nCode\nlibrary(data.table)\nlibrary(highcharter)\n\n\nRegistered S3 method overwritten by 'quantmod':\n  method            from\n  as.zoo.data.frame zoo"
  },
  {
    "objectID": "posts/04-highcharter_bar/index.html#the-data",
    "href": "posts/04-highcharter_bar/index.html#the-data",
    "title": "A Bidirectional Bar Chart using Highcharter",
    "section": "The data",
    "text": "The data\nThe data looks like this.\n\n\nCode\nbar_data &lt;- data.table(\n  donation_and_transplantation_summary = c(\n    \"Waiting for an organ\",\n    \"Opt-Out from the ODR\",\n    \"Deceased organ donor transplants\",\n    \"Died on the waiting list\",\n    \"Living organ donor transplants\",\n    \"Living donors\",\n    \"Opt-in to the Organ Donor Register (ODR)\",\n    \"Eligible deceased donors\",\n    \"Deceased donors\"\n  ),\n  black_percent = c(-11, -7, -10, -8, -4, -3, -2, -3, -1),\n  asian_percent = c(19, 18, 17, 13, 9, 8, 7, 7, 4)\n)\n\nbar_data\n\n\n       donation_and_transplantation_summary black_percent asian_percent\n                                     &lt;char&gt;         &lt;num&gt;         &lt;num&gt;\n1:                     Waiting for an organ           -11            19\n2:                     Opt-Out from the ODR            -7            18\n3:         Deceased organ donor transplants           -10            17\n4:                 Died on the waiting list            -8            13\n5:           Living organ donor transplants            -4             9\n6:                            Living donors            -3             8\n7: Opt-in to the Organ Donor Register (ODR)            -2             7\n8:                 Eligible deceased donors            -3             7\n9:                          Deceased donors            -1             4"
  },
  {
    "objectID": "posts/04-highcharter_bar/index.html#the-chart",
    "href": "posts/04-highcharter_bar/index.html#the-chart",
    "title": "A Bidirectional Bar Chart using Highcharter",
    "section": "The chart",
    "text": "The chart\n\n\nCode\nhighchart() |&gt;\n  # Set the chart type\n  hc_chart(type = \"bar\") |&gt;\n  # Provide x-axis categories (the labels for each bar)\n  hc_xAxis(\n    list(\n      categories = bar_data$donation_and_transplantation_summary,\n      reversed = FALSE\n    )\n    #list( # mirror axis on right side\n    #  opposite = TRUE,\n    #  categories = bar_data$donation_and_transplantation_summary,\n    #  reversed = FALSE,\n    #  linkedTo = 0\n    #  )\n    ) |&gt;\n  hc_yAxis(\n    gridLineColor = \"#f2f5f3\",\n    labels = list(\n      # positive values on both sides, appended with '%'\n      formatter = JS(\"function() { return Math.abs(this.value) + '%'; }\")\n    ),\n    plotBands = list( \n      list(\n      color = '#e2e1e1', from = 0, to = 9,\n      label = list(\n        text = \"9% Asian population\",\n        align = 'left',\n        y = -1,\n        x = 10\n        )\n      ),\n      list(\n      color = '#e2e1e1', from = -4, to = 0,\n      label = list(\n        text = \"4% Black population\",\n        align = 'right',\n        y = -1\n        )      \n      )\n    )\n  ) |&gt;\n  hc_plotOptions(\n    series = list(\n      # put bars for the same category on the same line\n      stacking = \"normal\",\n      pointPadding = 0.01,  # Padding between each column or bar, in x axis units... Defaults to 0.1.\n      groupPadding = 0.05  # Padding between each value groups, in x axis units... Defaults to 0.2.\n    )\n  ) |&gt;\n  hc_title(\n    text = \"&lt;span style='color:#62b19c;'&gt;Black&lt;/span&gt; and \n            &lt;span style='color:#bd82d5;'&gt;Asian&lt;/span&gt; \n            ethnic minorities are over-represented in transplant statistics\",\n    useHTML = TRUE,\n    style = list(\n      fontWeight = 'bold'\n    ),\n    align = \"left\"\n  )  |&gt;\n  hc_subtitle(\n    text = \"Percentage of these groups relative to the population of England and Wales in 2023/24\",\n    align = 'left'\n  ) |&gt;\n  hc_credits(\n    enabled = TRUE,\n    text = \"Ethnicity Differences in Organ Donation and Transplantion report for 2023/24 and 2021 population census estimates.\",\n    href = \"https://www.odt.nhs.uk/statistics-and-reports/annual-report-on-ethnicity-differences/\"  \n    ) |&gt;\n  hc_annotations(\n    list(\n        draggable = '',\n        labelOptions = list(\n          shape = 'connector',\n          justify = FALSE,\n          crop = TRUE,\n          style = list(\n            fontSize = \"10px\",\n            textOutline = \"1px white\",\n            fontWeight = \"normal\",\n            color = \"#4a4a4a\" \n            )\n        ),\n        labels =\n          list(point = list(xAxis = 0, yAxis = 0, y = 9, x = 6.5),\n               text = \"Within the grey zone shows&lt;br&gt;under-representation, while&lt;br&gt;outside the grey zone indicates&lt;br&gt;over-representation compared&lt;br&gt;to the population of England&lt;br&gt;and Wales.\",\n               x = 100, # offset in pixels\n               y = 50\n               )\n    )\n  ) |&gt;\n  hc_legend(\n    align = \"right\",\n    verticalAlign = \"bottom\",\n    layout = \"horizontal\"\n  ) |&gt;\n  hc_tooltip(\n    formatter = JS(\n      \"function() {\n         return '&lt;b&gt;' + this.series.name + '&lt;/b&gt;&lt;br/&gt;' +\n                this.point.category + ': ' +\n                Highcharts.numberFormat(Math.abs(this.point.y), 0) + '%';\n       }\"\n    )\n  ) |&gt;\n  hc_exporting(\n    accessibility = list(\n      enabled = TRUE # default value is TRUE\n      ),\n    enabled = TRUE,\n    filename = \"ethnic_minority_bar\"\n  ) |&gt;\n  hc_plotOptions(\n    accessibility = list(\n      enabled = TRUE,\n      keyboardNavigation = list(enabled = TRUE)\n      )\n    ) |&gt;\n  # Add a series of numeric values for the bars\n  hc_add_series(\n    name = \"Asian population\",\n    data = bar_data$asian_percent,\n    color = '#bd82d5'\n  ) |&gt;\n  hc_add_series(\n    name = \"Black population\",\n    data = bar_data$black_percent,\n    color = '#62b19c'\n  )"
  },
  {
    "objectID": "posts/04-highcharter_bar/index.html#fin",
    "href": "posts/04-highcharter_bar/index.html#fin",
    "title": "A Bidirectional Bar Chart using Highcharter",
    "section": "Fin",
    "text": "Fin\nI think the end result is pretty good."
  },
  {
    "objectID": "posts/03-highcharter_graphs/index.html",
    "href": "posts/03-highcharter_graphs/index.html",
    "title": "Some Highcharter Graphs",
    "section": "",
    "text": "In my previous post about {highcharter}, I considered changing some of the defaults for a scatter graph to make it look more appealing and be more accessible. This post will focus on plotting the following different types of graphs:\n\nBar charts, including grouped bar charts\nIcon plots\nLine graphs\nStream graphs\n\nFirst, we will load the packages we require in this post. The {highcharter} (Kunst 2022) and {tidyverse} (Wickham et al. 2019) packages are used throughout. The {medicaldata} package (Higgins 2021) is used to create the bar charts and (some of) the line graphs. The icon plots use data obtained via the {clmnis} package (Dempsey 2025).\n\nKunst, Joshua. 2022. Highcharter: A Wrapper for the ’Highcharts’ Library. https://CRAN.R-project.org/package=highcharter.\n\nWickham, Hadley, Mara Averick, Jennifer Bryan, Winston Chang, Lucy D’Agostino McGowan, Romain François, Garrett Grolemund, et al. 2019. “Welcome to the tidyverse.” Journal of Open Source Software 4 (43): 1686. https://doi.org/10.21105/joss.01686.\n\nHiggins, Peter. 2021. Medicaldata: Data Package for Medical Datasets. https://CRAN.R-project.org/package=medicaldata.\n\n\nCode\nlibrary(highcharter)\nlibrary(paletteer) # colour palettes\nlibrary(tidyverse)\nlibrary(gapminder)\n\n# medical data package\n# use 'remotes::install_github(\"higgi13425/medicaldata\")' to access the 'thiomon' dataset\nlibrary(medicaldata)\n\n# obtaining MP information\n# remotes::install_github(\"houseofcommonslibrary/clmnis\")\nlibrary(clmnis)\n\nlibrary(fontawesome)"
  },
  {
    "objectID": "posts/03-highcharter_graphs/index.html#introduction",
    "href": "posts/03-highcharter_graphs/index.html#introduction",
    "title": "Some Highcharter Graphs",
    "section": "",
    "text": "In my previous post about {highcharter}, I considered changing some of the defaults for a scatter graph to make it look more appealing and be more accessible. This post will focus on plotting the following different types of graphs:\n\nBar charts, including grouped bar charts\nIcon plots\nLine graphs\nStream graphs\n\nFirst, we will load the packages we require in this post. The {highcharter} (Kunst 2022) and {tidyverse} (Wickham et al. 2019) packages are used throughout. The {medicaldata} package (Higgins 2021) is used to create the bar charts and (some of) the line graphs. The icon plots use data obtained via the {clmnis} package (Dempsey 2025).\n\nKunst, Joshua. 2022. Highcharter: A Wrapper for the ’Highcharts’ Library. https://CRAN.R-project.org/package=highcharter.\n\nWickham, Hadley, Mara Averick, Jennifer Bryan, Winston Chang, Lucy D’Agostino McGowan, Romain François, Garrett Grolemund, et al. 2019. “Welcome to the tidyverse.” Journal of Open Source Software 4 (43): 1686. https://doi.org/10.21105/joss.01686.\n\nHiggins, Peter. 2021. Medicaldata: Data Package for Medical Datasets. https://CRAN.R-project.org/package=medicaldata.\n\n\nCode\nlibrary(highcharter)\nlibrary(paletteer) # colour palettes\nlibrary(tidyverse)\nlibrary(gapminder)\n\n# medical data package\n# use 'remotes::install_github(\"higgi13425/medicaldata\")' to access the 'thiomon' dataset\nlibrary(medicaldata)\n\n# obtaining MP information\n# remotes::install_github(\"houseofcommonslibrary/clmnis\")\nlibrary(clmnis)\n\nlibrary(fontawesome)"
  },
  {
    "objectID": "posts/03-highcharter_graphs/index.html#bar-charts",
    "href": "posts/03-highcharter_graphs/index.html#bar-charts",
    "title": "Some Highcharter Graphs",
    "section": "Bar charts",
    "text": "Bar charts\nFor the bar charts, I’m using data obtained from the {medicaldata} package. Loading the Covid data1, and ensuring factors are coded correctly.\n1 Description of the dataset can be found here\n\nCode\ncovid &lt;- tibble(medicaldata::covid_testing)\n\ncovid &lt;- covid |&gt;\n  mutate(across(c(gender, test_id, demo_group, drive_thru_ind, result, payor_group, patient_class), as_factor))\n\n# look at levels of the factors\n#sapply(covid[, c(\"gender\", \"test_id\", \"demo_group\", \"drive_thru_ind\", \"result\", \"payor_group\", \"patient_class\")], levels)\n\ncovid\n\n\n\n  \n\n\n\nLet’s start with a simple bar chart, showing the frequency of negative and positive Covid results.\nFirst we create counts of positive, negative and invalid results.\n\n\nCode\nresult_counts &lt;- covid |&gt;\n  count(result) |&gt;\n  # capitalise first letter\n  mutate(result = str_to_title(as.character(result))) |&gt;\n  arrange(desc(n))\n\n\n\n\nCode\n# Create the bar chart\nhchart(\n    result_counts,\n    type = \"bar\",\n    hcaes(x = result, y = n),\n    name = \"Results\"\n  ) |&gt;\n  hc_title(text = \"Results of Covid Tests\") |&gt;\n  hc_xAxis(title = list(text = \"Result\")) |&gt;\n  hc_yAxis(title = list(text = \"Count\")) |&gt;\n  hc_colors(\"#003087\") |&gt;\n  # a source\n  hc_credits(\n    text = \"Data obtained from the {medicaldata} package\",\n    href = \"https://higgi13425.github.io/medicaldata/\",\n    enabled = TRUE\n    ) |&gt;\n  hc_exporting(\n    accessibility = list(\n      enabled = TRUE # default value is TRUE\n      ),\n    enabled = TRUE,\n    filename = \"covid_bar\"\n  ) |&gt;\n  hc_plotOptions(\n    accessibility = list(\n      enabled = TRUE,\n      keyboardNavigation = list(enabled = TRUE)\n      )\n    )\n\n\n\n\n\n\n\nGrouped bar chart\nGroup results by gender.\n\n\nCode\nresult_counts_gender &lt;- covid |&gt;\n  group_by(gender) |&gt;\n  count(result) |&gt;\n  # capitalise first letter\n  mutate(result = str_to_title(as.character(result)))\n\n\n\n\n\n\n\n\nThe hover box issues\n\n\n\nThe hard part here seems to be getting the hover box to output the correct things. Specifically, I don’t know how to get the names of the y-axis titles (“Positive”, etc.), without doing nested if statements. It must involve the formatter but I’m not sure how.\nFIXED: use this.key to get the names.\n\n\n\n\nCode\nhchart(\n  result_counts_gender,\n  type = \"bar\",\n  hcaes(x = result, y = n, group = gender) \n  ) |&gt;\n  hc_colors(c(\"#003087\", \"#006747\")) |&gt;\n  hc_title(text = \"Lots of people don't have Covid\",\n           align = \"left\") |&gt;\n  hc_subtitle(text = \"A bar chart showing Covid test results, split by gender.\",\n              align = \"left\") |&gt;\n  hc_xAxis(title = list(text = \"Result\")) |&gt;\n  hc_yAxis(title = list(text = \"Count\")) |&gt;\n  # a source\n  hc_credits(\n    text = \"Data obtained from the {medicaldata} package\",\n    href = \"https://higgi13425.github.io/medicaldata/\",\n    enabled = TRUE\n    ) |&gt;\n   hc_tooltip(\n      formatter = JS(\"function () {\n       if (this.series.name == 'male') {\n        return `&lt;b&gt;Male&lt;/b&gt;&lt;/br&gt;${this.y} ${this.key} results`\n      } else if (this.series.name == 'female') {\n        return `&lt;b&gt;Female&lt;/b&gt;&lt;/br&gt; ${this.y} ${this.key} results`\n      }}\")\n   ) |&gt;\n  hc_exporting(\n    accessibility = list(\n      enabled = TRUE # default value is TRUE\n      ),\n    enabled = TRUE,\n    filename = \"covid_bar\"\n  ) |&gt;\n  hc_plotOptions(\n    accessibility = list(\n      enabled = TRUE,\n      keyboardNavigation = list(enabled = TRUE)\n      )\n    )"
  },
  {
    "objectID": "posts/03-highcharter_graphs/index.html#icons-plot",
    "href": "posts/03-highcharter_graphs/index.html#icons-plot",
    "title": "Some Highcharter Graphs",
    "section": "Icons plot",
    "text": "Icons plot\nLet’s look at the gender split in parliament as of 31st December 2024. We can extract the data using {clmnis} (Dempsey 2025), which is an R package for downloading data from the UK Parliament’s Members Names Information Service (MNIS).\n\nDempsey, Noel. 2025. Clmnis: An r Package for Downloading Data from the Parliamentary Members Names Information Service. https://github.com/houseofcommonslibrary/clmnis.\nObtaining the data:\n\n\nCode\nmps &lt;- clmnis::fetch_mps(on_date = \"2024-12-31\")\n\nmps\n\n\n\n  \n\n\n\n\n\nCode\nmps_gender &lt;- mps |&gt;\n  count(gender) |&gt;\n  mutate(\n    gender = case_match(\n      gender,\n      \"M\" ~ \"Male MPs\",\n      \"F\" ~ \"Female MPs\"\n    )\n  ) |&gt;\n  add_column(col = c(\"#4477AA\", \"#EE6677\"))\n        \nmps_gender\n\n\n\n  \n\n\n\n\nA basic icon chart\nPlotting a simple icon chart. Choose between the “parliament view” and the “circular view” by selecting the relevant tab below.\n\nParliament viewCircle view\n\n\n\n\nCode\nhchart(\n  mps_gender,\n  \"item\",\n  hcaes(\n    name = gender,\n    y = n,\n    color = col\n  ),\n  name = \"Number of MPs\",\n  showInLegend = TRUE,\n  size = \"100%\",\n  center = list(\"50%\", \"75%\"),\n  startAngle = -100,\n  endAngle  = 100\n) %&gt;%\n  hc_title(\n    text = \"Male MPs make up a significant majority of the House of Commons\",\n    align = \"left\"\n    ) %&gt;%\n  hc_subtitle(\n    text = \"An item chart showing the proportion of male and femal MPs in the House of Commons, on 31st December 2024.\",\n    align = \"left\"\n    ) |&gt;\n  hc_legend(labelFormat = '{name} &lt;span style=\"opacity: 0.4\"&gt;{y}&lt;/span&gt;') |&gt;\n  hc_exporting(\n    accessibility = list(\n      enabled = TRUE # default value is TRUE\n      ),\n    enabled = TRUE,\n    filename = \"mp_icon_plot\"\n  ) |&gt;\n  hc_plotOptions(\n    accessibility = list(\n      enabled = TRUE,\n      keyboardNavigation = list(enabled = TRUE)\n      )\n    )\n\n\n\n\n\n\n\n\nTo change the plot to a circular layout, set startAngle = -180 and endAngle = 180 and change the center argument.\n\n\nCode\nhchart(\n  mps_gender,\n  \"item\",\n  hcaes(\n    name = gender,\n    y = n,\n    color = col\n  ),\n  name = \"Number of MPs\",\n  showInLegend = TRUE,\n  size = \"100%\",\n  center = list(\"50%\", \"50%\"),\n  startAngle = -180,\n  endAngle  = 180\n) %&gt;%\n  hc_title(\n    text = \"Male MPs make up a significant majority of the House of Commons\",\n    align = \"left\"\n    ) %&gt;%\n  hc_subtitle(\n    text = \"An item chart showing the proportion of male and femal MPs in the House of Commons, on 31st December 2024.\",\n    align = \"left\"\n    ) |&gt;\n  hc_legend(labelFormat = '{name} &lt;span style=\"opacity: 0.4\"&gt;{y}&lt;/span&gt;') |&gt;\n  hc_exporting(\n    accessibility = list(\n      enabled = TRUE # default value is TRUE\n      ),\n    enabled = TRUE,\n    filename = \"mp_icon_plot\"\n  ) |&gt;\n  hc_plotOptions(\n    accessibility = list(\n      enabled = TRUE,\n      keyboardNavigation = list(enabled = TRUE)\n      )\n    )\n\n\n\n\n\n\n\n\n\n\n\nAdding symbols to the icon chart\nWhat if we want female and male symbols instead of circles, and the icons arranges in a rectangle?\nFirst, lets add the icons to the tibble. We will use the {fontawesome} package (Iannone 2024), alongside the function given in the {highcharter} vignette to obtain the symbols.\n\nIannone, Richard. 2024. Fontawesome: Easily Work with ’Font Awesome’ Icons. https://github.com/rstudio/fontawesome.\n\n\nCode\nfa_to_png_to_datauri &lt;- function(name, ...) {\n  tmpfl &lt;- tempfile(fileext = \".png\")\n  fontawesome::fa_png(name, file = tmpfl, ...)\n  knitr::image_uri(tmpfl)\n\n}\n\n\nAdding the ‘person’ and ‘person-dress’ symbols to the tibble.\n\n\nCode\nmps_gender_icon &lt;- mps_gender |&gt;\n  add_column(faico = c(\"person-dress\", \"person\"))\n\nmps_gender_icon &lt;- mps_gender_icon |&gt;\n  mutate(\n    uri = map2_chr(faico, col, ~fa_to_png_to_datauri(.x, fill = .y)),\n    marker = map(uri, ~ list(symbol = str_glue(\"url({data_uri})\", data_uri = .x)))\n  )\n\n\nCreating the new icon plot.\n\n\nCode\nhchart(\n  mps_gender_icon,\n  \"item\",\n  hcaes(\n    name = gender,\n    y = n,\n    color = col\n  ),\n  name = \"Number of MPs\",\n  showInLegend = TRUE,\n  size = \"100%\"\n) |&gt;\n  hc_title(\n    text = \"Male MPs make up a significant majority of the House of Commons\",\n    align = \"left\"\n    ) |&gt;\n  hc_subtitle(\n    text = \"An item chart showing the proportion of male and femal MPs in the House of Commons, on 31st December 2024.\",\n    align = \"left\"\n    ) |&gt;\n  hc_legend(labelFormat = '{name} &lt;span style=\"opacity: 0.4\"&gt;{y}&lt;/span&gt;') |&gt;\n  hc_plotOptions(\n    item = list(\n      layout = \"vertical\",\n      rows = 18 # Specify the number of rows here\n    )\n  ) |&gt;\n  hc_exporting(\n    accessibility = list(\n      enabled = TRUE # default value is TRUE\n      ),\n    enabled = TRUE,\n    filename = \"mp_icon_plot\"\n  ) |&gt;\n  hc_plotOptions(\n    accessibility = list(\n      enabled = TRUE,\n      keyboardNavigation = list(enabled = TRUE)\n      )\n    )"
  },
  {
    "objectID": "posts/03-highcharter_graphs/index.html#line-graphs",
    "href": "posts/03-highcharter_graphs/index.html#line-graphs",
    "title": "Some Highcharter Graphs",
    "section": "Line graphs",
    "text": "Line graphs\nUsing data obtained from the {gapminder} package (Bryan 2023), we will produce a line graph. A few new things here:\n\nBryan, Jennifer. 2023. Gapminder: Data from Gapminder. https://CRAN.R-project.org/package=gapminder.\n\nWe have used the {paletteer} package (Hvitfeldt 2021) to obtain a colour palette.\nWe have added labels to the lines directly, using plotOptions.series.label.\nWe have set the linewidth directed, in plotOptions.\nWe have removed markers from the lines except when hovered over, in plotOptions.\n\n\nHvitfeldt, Emil. 2021. Paletteer: Comprehensive Collection of Color Palettes. https://github.com/EmilHvitfeldt/paletteer.\n\n\nCode\ngapminder_line &lt;- gapminder |&gt;\n  filter(country %in% c(\"United Kingdom\",\"France\",\"Germany\",\"Italy\",\"Netherlands\"))\n\nhchart(gapminder_line, \n       \"line\",\n        hcaes(x = year, y = pop, group = country)) |&gt;\n  hc_title(\n    text = \"The Netherlands has a much smaller population than Germany.\",\n    align = \"left\"\n    ) |&gt;\n  hc_subtitle(\n    text = \"A line chart showing changes in population between 1952 and 2007.\",\n    align = \"left\"\n    ) |&gt;\n  hc_xAxis(title = list(text = \"Year\")) |&gt;\n  hc_yAxis(title = list(text = \"Population\")) |&gt;\n  # a source\n  hc_credits(\n    text = \"Data obtained from the {gapminder} package\",\n    href = \"https://www.gapminder.org/\",\n    enabled = TRUE\n    ) |&gt;\n  hc_colors(colors = as.character(paletteer::paletteer_d(\"lisa::FridaKahlo\"))) |&gt;\n  hc_exporting(\n    accessibility = list(\n      enabled = TRUE # default value is TRUE\n      ),\n    enabled = TRUE,\n    filename = \"population_line\"\n  ) |&gt;\n  hc_plotOptions(\n    series = list(\n   label = list(\n        enabled = TRUE, # add labels to lines\n        style = list(\n          fontWeight = \"bold\",\n          color = \"#333\"\n        ),\n        connectorAllowed = FALSE # include line connecting label to series?\n      ),\n      lineWidth = 2,\n      marker = list(\n        enabled = FALSE, # remove markers\n        symbol = \"circle\",\n        states = list(\n          hover = list(\n            enabled = TRUE # enable markers if hovered over\n          )\n        )\n      )),\n    accessibility = list(\n      enabled = TRUE,\n      keyboardNavigation = list(enabled = TRUE)\n      )\n    )"
  },
  {
    "objectID": "posts/03-highcharter_graphs/index.html#stream-graphs",
    "href": "posts/03-highcharter_graphs/index.html#stream-graphs",
    "title": "Some Highcharter Graphs",
    "section": "Stream graphs",
    "text": "Stream graphs\nCopying the line graph we produced above.\n\n\nCode\nhchart(gapminder_line, \n       \"streamgraph\", zoomType = \"x\",\n        hcaes(x = year, y = pop, group = country)) |&gt;\n  hc_title(\n    text = \"The populations in these countries are relatively steady over time.\",\n    align = \"left\"\n    ) |&gt;\n  hc_subtitle(\n    text = \"A line chart showing changes in population between 1952 and 2007.\",\n    align = \"left\"\n    ) |&gt;\n  hc_xAxis(title = list(text = \"Year\")) |&gt;\n  hc_yAxis(visible = FALSE, \n           startOnTick = FALSE, endOnTick = FALSE, \n           title = list(text = \"Population\")) |&gt;\n  # a source\n  hc_credits(\n    text = \"Data obtained from the {gapminder} package\",\n    href = \"https://www.gapminder.org/\",\n    enabled = TRUE\n    ) |&gt;\n  hc_colors(colors = as.character(paletteer::paletteer_d(\"lisa::FridaKahlo\"))) |&gt;\n  hc_exporting(\n    accessibility = list(\n      enabled = TRUE # default value is TRUE\n      ),\n    enabled = TRUE,\n    filename = \"population_line\"\n  ) |&gt;\n  hc_plotOptions(\n    series = list(\n   label = list(\n        enabled = TRUE, # add labels to lines\n        style = list(\n          fontWeight = \"bold\",\n          color = \"#555555\"\n        ),\n        connectorAllowed = FALSE # include line connecting label to series?\n      ),\n      lineWidth = 2,\n      marker = list(\n        enabled = FALSE, # remove markers\n        symbol = \"circle\",\n        states = list(\n          hover = list(\n            enabled = FALSE # enable markers if hovered over\n          )\n        )\n      )),\n    accessibility = list(\n      enabled = TRUE,\n      keyboardNavigation = list(enabled = TRUE)\n      )\n    )\n\n\n\n\n\n\nCopying the example given in the Highchart demos. First, we will create a list of data – medals won by countries in the Winter Olympics, which is taken from Olympedia.\n\n\nCode\ncustom_colors &lt;- as.character(paletteer_d(`\"awtools::bpalette\"`, n = 3))\n  \n# Categories\ncategories &lt;- c(\n  '',\n  '1924 Chamonix', '1928 St. Moritz', '1932 Lake Placid', \n  '1936 Garmisch-Partenkirchen', '1940 &lt;i&gt;Cancelled (Sapporo)&lt;/i&gt;', \n  '1944 &lt;i&gt;Cancelled (Cortina d\\'Ampezzo)&lt;/i&gt;', '1948 St. Moritz', \n  '1952 Oslo', '1956 Cortina d\\'Ampezzo', '1960 Squaw Valley', \n  '1964 Innsbruck', '1968 Grenoble', '1972 Sapporo', \n  '1976 Innsbruck', '1980 Lake Placid', '1984 Sarajevo', \n  '1988 Calgary', '1992 Albertville', '1994 Lillehammer', \n  '1998 Nagano', '2002 Salt Lake City', '2006 Turin', \n  '2010 Vancouver', '2014 Sochi', '2018 PyeongChang', \n  '2022 Beijing'\n)\n\n# medal data\nmedal_data &lt;- list(\n  list(name = \"Finland\", \n       data = c(0, 11, 4, 3, 6, 0, 0, 6, 9, 7, 8, 10, 5, 5, 7, 9, 13, 7, 7, 6, 12, 7, 9, 5, 5, 6, 8)),\n  list(name = \"Austria\", \n       data = c(0, 3, 4, 2, 4, 0, 0, 8, 8, 11, 6, 12, 11, 5, 6, 7, 1, 10, 21, 9, 17, 17, 23, 16, 17, 14, 18)),\n  list(name = \"Sweden\", \n       data = c(0, 2, 5, 3, 7, 0, 0, 10, 4, 10, 7, 7, 8, 4, 2, 4, 8, 6, 4, 3, 3, 7, 14, 11, 15, 14, 18))\n)\n\n\nNow we will create the stream graph. A few novel things here:\n\nI built the graph before adding the data. Note that the data is only added in the very last line, using `hc_add_series_list()\nAnnotations were added using hc_annotations().\n\n\n\nCode\n# Create the chart\nhighchart() |&gt;\n  hc_chart(type = \"streamgraph\", zoomType = \"x\", marginBottom = 30) |&gt;\n  hc_colors(colors = custom_colors) |&gt;\n  hc_title(text = \"Winter Olympic Medal Wins\", align = \"left\", floating = TRUE) |&gt;\n  hc_subtitle(\n    text = 'Source: &lt;a href=\"https://www.olympedia.org/statistics\"&gt;olympedia.org&lt;/a&gt;', \n    align = \"left\", y = 30, floating = TRUE\n  ) |&gt;\n  hc_xAxis(\n    categories = categories, \n    crosshair = TRUE,\n    labels = list(\n      align = \"left\", \n      rotation = 270, \n      reserveSpace = FALSE),\n    lineWidth = 0, # remove x-axis line\n    tickWidth = 0 # remove x-axis tick\n  ) |&gt;\n  hc_yAxis(visible = FALSE, \n           startOnTick = FALSE, endOnTick = FALSE, \n           minPadding = 0.1, maxPadding = 0.15) |&gt;\n  hc_legend(enabled = FALSE) |&gt;\n  hc_annotations(\n    list(\n      labels = list(\n        list(point = list(x = 5.5, xAxis = 0, y = 0, yAxis = 0), \n             text = \"Cancelled&lt;br&gt;during&lt;br&gt;World War II\"),\n        list(point = list(x = 18, xAxis = 0, y = 15, yAxis = 0), \n             text = \"Soviet Union fell,&lt;br&gt;Germany united\"),\n        list(point = list(x = 24.25, xAxis = 0, y = 20, yAxis = 0), \n             text = \"Russia banned from&lt;br&gt;the Olympic Games&lt;br&gt; in 2017\")\n      )\n    )\n  ) |&gt;\n  hc_plotOptions(\n    series = list(\n      label = list(\n        minFontSize = 5, \n        maxFontSize = 15, \n        style = list(color = \"rgba(255,255,255,0.75)\")),\n      accessibility = list(exposeAsGroupOnly = TRUE)\n    )\n  ) |&gt;\n  hc_add_series_list(medal_data)"
  },
  {
    "objectID": "posts/03-highcharter_graphs/index.html#other-charts",
    "href": "posts/03-highcharter_graphs/index.html#other-charts",
    "title": "Some Highcharter Graphs",
    "section": "Other charts",
    "text": "Other charts\nI have shamelessly stolen this next chart from Joshua Kunst who created it in a {highcharter} article, and in turn stole the idea from the Wall Street Journal. But, it is such a nice chart that I can’t not reproduce it here.\n\n\nCode\ndata(vaccines)\n\nfntltp &lt;- JS(\"function(){\n  return this.point.x + ' ' +  this.series.yAxis.categories[this.point.y] + ': ' +\n  Highcharts.numberFormat(this.point.value, 2);\n}\")\n\nplotline &lt;- list(\n  color = \"#fde725\", value = 1963, width = 2, zIndex = 5,\n  label = list(\n    text = \"Vaccine Intoduced\", verticalAlign = \"top\",\n    style = list(color = \"#606060\"), textAlign = \"left\",\n    rotation = 0, y = -5\n  )\n)\n\nhchart(\n  vaccines, \n  \"heatmap\", \n  hcaes(\n    x = year,\n    y = state, \n    value = count\n    )\n  ) |&gt;\n  hc_colorAxis(\n    stops = color_stops(10, viridisLite::inferno(10, direction = -1)),\n    type = \"logarithmic\"\n  ) |&gt;\n  hc_yAxis(\n    title = list(text = \"\"),\n    reversed = TRUE, \n    offset = -20,\n    tickLength = 0,\n    gridLineWidth = 0, \n    minorGridLineWidth = 0,\n    labels = list(style = list(fontSize = \"9px\"))\n  ) |&gt;\n  hc_tooltip(\n    formatter = fntltp\n    ) |&gt;\n  hc_xAxis(\n    plotLines = list(plotline)) |&gt;\n  hc_title(\n    text = \"Infectious Diseases and Vaccines\"\n    ) |&gt;\n  hc_subtitle(\n    text = \"Number of cases per 100,000 people\"\n  ) |&gt; \n  hc_legend(\n    layout = \"horizontal\",\n    verticalAlign = \"top\",\n    align = \"left\",\n    valueDecimals = 0\n  ) |&gt;\n  hc_size(height = 900)  |&gt;\n  hc_exporting(\n    accessibility = list(\n      enabled = TRUE # default value is TRUE\n      ),\n    enabled = TRUE,\n    filename = \"vaccines\"\n  ) |&gt;\n  hc_plotOptions(\n    accessibility = list(\n      enabled = TRUE,\n      keyboardNavigation = list(enabled = TRUE)\n      )\n    )"
  },
  {
    "objectID": "posts/02-mandelian_randomisation/index.html",
    "href": "posts/02-mandelian_randomisation/index.html",
    "title": "A First Foray into Genetics, GWAS, and Mendelian Randomisation",
    "section": "",
    "text": "In the previous few weeks I have been trying to learn about Mendelian Randomisation, which has resulted in me doing a whistle-stop tour around genetics, codons, and genetic-wide association studies (GWAS). This post is a collection of my notes and thoughts.1\n1 Please let me know if there are any mistakes or misconceptions"
  },
  {
    "objectID": "posts/02-mandelian_randomisation/index.html#introduction",
    "href": "posts/02-mandelian_randomisation/index.html#introduction",
    "title": "A First Foray into Genetics, GWAS, and Mendelian Randomisation",
    "section": "",
    "text": "In the previous few weeks I have been trying to learn about Mendelian Randomisation, which has resulted in me doing a whistle-stop tour around genetics, codons, and genetic-wide association studies (GWAS). This post is a collection of my notes and thoughts.1\n1 Please let me know if there are any mistakes or misconceptions"
  },
  {
    "objectID": "posts/02-mandelian_randomisation/index.html#genetics-for-dummys",
    "href": "posts/02-mandelian_randomisation/index.html#genetics-for-dummys",
    "title": "A First Foray into Genetics, GWAS, and Mendelian Randomisation",
    "section": "Genetics for dummys",
    "text": "Genetics for dummys\n\n\n\n\n\n\nNote\n\n\n\nBefore diving in, it’s worth remarking that the field of genetics was created before anyone had any idea about the structure of a cell, what DNA looked like, and what chromosomes were. This means the language around this topic can be somewhat confusing for a newcomer, as old terms are still floating around, and overlapping with newer more precise terms.\n\n\nLet’s start by describing the basic mechanics of genetic material and cells. In humans, most cell contains DNA, which is packaged in 23 chromosomes2. DNA is a long code created from four nucleotides – adenine (A), guanine (G), cytosine (C), and thymine (T) – which are paired with each other (AT and CG) to create base pairs. Parts of the DNA do a specific job, and are known as genes. These genes either code for proteins, or help control other genes. Genes are small sections of DNA that have the ability to be copied into an RNA sequence, which can then encode for proteins (or perform other tasks).\n2 by being tightly coiled around proteins known as histones3 The full table showing these combinations can be seen hereA single-nucleotide polymorphism (SNP) is when there is a substitution in a single nucleotide. A SNP in a gene can create differences within populations, for example in the ability to metabolise alcohol. Most of the time, however, they do not create any differences, as when the RNA from genes are read, they are done in codons. A codon is a set of three base pairs, and therefore there are \\(4^3 = 64\\) different combinations of the four nucleotides (\\(61\\) of which specify amino acids). However, as there are only \\(20\\) amino acids, there are many codons with different base pairs that produce the same amino acids. For example, UCU, UCC, UCA, UCG, AGU, AGC all produce the Serine amino acid.3\n\nA short history\nLets start with Gregor Mendel – the “father of modern genetics” and well known for his experiments into the inheritance of pea plants. I won’t go into detail on him, as Wikipedia can do that for me. However, two quick points to make:\n\nThe Laws of Inheritance are important pre-requisite conditions for Mendelian Randomisation to work.\nThe genius of Mendel was his ability to understand that the underlying process was random, and he was only observing a realisation of this random process.\n\nThe double-helix structure of DNA was discovered by Rosalind Franklin, James Watson and Francis Crick in 1953. This knowledge of the structure allowed the further discoveries of how proteins are translated from RNA, which is transcribed by DNA.\n\nBiobanks\nIn the last twenty years or so, large biobanks have been created. These store the genetic and health information of individuals, either at a single point in time or with a temporal aspect. Two examples of large biobanks are:\n\nThe UK Biobank has information on around half-a-million individuals aged between 40 and 69.\nThe Avon Longitudinal Study of Parents and Children. Here, more than 14,000 pregnant women were recruited into the study in 1991/92, with their children, and grandchildren, being followed up in detail.\n\nOne important caveat for these biobanks when using them for research is that they are not representative of the population of the UK. For example, it is known that the individuals in the UK Biobank are more likely to be in a higher social-economic bracket, with fewer lung cancers and other health issues than the general population. This makes performing analysis and obtaining generalisable result (using GWAS4 and Mendelian Randomisation) more difficult.\n4 genome-wise association studies\n\nGenome-wise associated studies\nGenome-wide association studies (GWAS) attempt to find associations between genetic variants and phenotypes. The genetic variants considered are usually SNPs, as opposed to indels5. As biobank sequencing is normally short-read (i.e. only a small section of DNA is read at a time) and the location of these short-reads are random,6 it is trickier to notice indels compared to SNPs. It is also worth noting here that when an individual’s genome is sequenced, the result isn’t the sequence of DNA in a specific cell, but instead is an average. This means that the SNPs in the sequences obtained were present in most of the cells within the individual so most likely have been there since the very early cell division stages. Therefore, if certain SNPs are associated with phenotypes, then the relationship can be thought of a “lifetime” association.\n5 insertions and deletions6 I am not sure if they are truly random along the whole of the DNA - it might just be that there is some uncertainty in the exact location"
  },
  {
    "objectID": "posts/02-mandelian_randomisation/index.html#mendelian-randomisation",
    "href": "posts/02-mandelian_randomisation/index.html#mendelian-randomisation",
    "title": "A First Foray into Genetics, GWAS, and Mendelian Randomisation",
    "section": "Mendelian Randomisation",
    "text": "Mendelian Randomisation"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "pblog",
    "section": "",
    "text": "Model Fitting and Validation\n\n\nSome critiques of data-splitting and the stepwise procedure\n\n\n\ncode\n\n\nr\n\n\nstatistics\n\n\nmodel fitting\n\n\nmodel validation\n\n\n\n\n\n\n\n\n\nMar 5, 2025\n\n\nPaul Smith\n\n\n\n\n\n\n\n\n\n\n\n\nModel Fitting and Validation\n\n\nSimulating the effect of data-splitting and stepwise selection on the lung dataset\n\n\n\ncode\n\n\nr\n\n\nstatistics\n\n\nmodel fitting\n\n\nmodel validation\n\n\n\n\n\n\n\n\n\nMar 5, 2025\n\n\nPaul Smith\n\n\n\n\n\n\n\n\n\n\n\n\nGetting Started with {mlr3}\n\n\n01 Data and Basic Modeling\n\n\n\ncode\n\n\nr\n\n\nmachine learning\n\n\nmlr3\n\n\n\n\n\n\n\n\n\nMar 3, 2025\n\n\nPaul Smith\n\n\n\n\n\n\n\n\n\n\n\n\nA Bidirectional Bar Chart using Highcharter\n\n\n\n\n\n\ncode\n\n\ngraphics\n\n\nr\n\n\n\n\n\n\n\n\n\nFeb 19, 2025\n\n\nPaul Smith\n\n\n\n\n\n\n\n\n\n\n\n\nSome Highcharter Graphs\n\n\n\n\n\n\ncode\n\n\ngraphics\n\n\nr\n\n\n\n\n\n\n\n\n\nJan 12, 2025\n\n\nPaul Smith\n\n\n\n\n\n\n\n\n\n\n\n\nA First Foray into Genetics, GWAS, and Mendelian Randomisation\n\n\n\n\n\n\ngenetics\n\n\ngwas\n\n\nmendelian randomisation\n\n\n\n\n\n\n\n\n\nJan 11, 2025\n\n\nPaul Smith\n\n\n\n\n\n\n\n\n\n\n\n\nGetting Started with Accessible Highcharter\n\n\n\n\n\n\ncode\n\n\naccessibility\n\n\ngraphics\n\n\nr\n\n\n\n\n\n\n\n\n\nDec 16, 2024\n\n\nPaul Smith\n\n\n\n\n\n\nNo matching items\n\nCitationBibTeX citation:@online{untitled,\n  author = {},\n  title = {Pblog},\n  url = {https://pws3141.github.io/blog/},\n  langid = {en}\n}\nFor attribution, please cite this work as:\n“Pblog.” n.d. https://pws3141.github.io/blog/."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "This is a little space on the internet where probably nobody walks except me and my thoughts. Mainly about maths and R, sometimes both, very occasionally neither. I hope some of these posts are useful to someone."
  },
  {
    "objectID": "about.html#education",
    "href": "about.html#education",
    "title": "About",
    "section": "Education",
    "text": "Education\nUniversity of Leeds | PhD in Statistics | September 2016 - August 2020\nUniversity of Bristol | MMath | September 2011 - June 2015\nUniversity of Hull | PGCE | September 2020 - June 2021"
  },
  {
    "objectID": "about.html#experience",
    "href": "about.html#experience",
    "title": "About",
    "section": "Experience",
    "text": "Experience\nNHS Blood and Transplant, Bristol | Statistician | November 2023 - present\nEquality and Human Rights Commission, Cardiff | Statistician | April 2023 - October 2023 (Maternity Cover)\nSecondary School, Bath | Maths Teacher | September 2020 - August 2022\nKPMG, London | Investment Advisor | September 2015 - August 2016"
  },
  {
    "objectID": "posts/01-highcharter/index.html",
    "href": "posts/01-highcharter/index.html",
    "title": "Getting Started with Accessible Highcharter",
    "section": "",
    "text": "Inspired by the quarto and me blog, I am looking into using {highcharter} (Kunst 2022). This package is a wrapper for Highcharts – an interactive charting library1.\n\nKunst, Joshua. 2022. Highcharter: A Wrapper for the ’Highcharts’ Library. https://CRAN.R-project.org/package=highcharter.\n1 this needs a license for commercial and governmental useIn this post I will only be considering a scatter graph. Different plots – including survival curves – will come later.\n\n\n\nMy main requirements are mostly subjective:\n\nLooks nice\nIs interactive in a nice and obvious way\nIs accessible, following advice given by the Government Analysis Function"
  },
  {
    "objectID": "posts/01-highcharter/index.html#introduction",
    "href": "posts/01-highcharter/index.html#introduction",
    "title": "Getting Started with Accessible Highcharter",
    "section": "",
    "text": "Inspired by the quarto and me blog, I am looking into using {highcharter} (Kunst 2022). This package is a wrapper for Highcharts – an interactive charting library1.\n\nKunst, Joshua. 2022. Highcharter: A Wrapper for the ’Highcharts’ Library. https://CRAN.R-project.org/package=highcharter.\n1 this needs a license for commercial and governmental useIn this post I will only be considering a scatter graph. Different plots – including survival curves – will come later.\n\n\n\nMy main requirements are mostly subjective:\n\nLooks nice\nIs interactive in a nice and obvious way\nIs accessible, following advice given by the Government Analysis Function"
  },
  {
    "objectID": "posts/01-highcharter/index.html#getting-started-with-highcharter",
    "href": "posts/01-highcharter/index.html#getting-started-with-highcharter",
    "title": "Getting Started with Accessible Highcharter",
    "section": "Getting started with {highcharter}",
    "text": "Getting started with {highcharter}\nLets use the {palmerpenguins} data2 (Horst, Hill, and Gorman 2020).\n2 because penguins are nicer than eugenicists\nHorst, Allison Marie, Alison Presmanes Hill, and Kristen B Gorman. 2020. Palmerpenguins: Palmer Archipelago (Antarctica) Penguin Data. https://doi.org/10.5281/zenodo.3960218.\nThis is also the first time I have used the base R pipe |&gt;, after a life-time (well, 5 years) of using %&gt;%. The differences between the two are explain in this tidyverse blog. This means that the below code will not work on R versions prior to 4.1.0.\n\n\nCode\nlibrary(highcharter)\nlibrary(palmerpenguins)\n\n#data(package = 'palmerpenguins')\n\npenguins\n\n\n\n  \n\n\n\nA basic scatter graph, using the hchart function. Here, hcaes is similar in spirit to ggplot’s aes.\n\n\nCode\nhchart(penguins,\"scatter\", \n       hcaes(x = flipper_length_mm, y = bill_length_mm, group = species))\n\n\n\n\n\n\n\n\n\n\nSimple changes\nLets change a few things about the plot:\n\nAdd \\(x\\) and \\(y\\) axis labels;\nAdd a title and subtitle;\nAdd a source;\nChange the colours to the Government Analysis Function categorical data colour palette;\nMake the hover box specify ‘flipper length’ and ‘bill length’.\n\n\n\n\n\n\nGovernment analysis function colour palette\n\n\n\n\nCode\nhc_penguins &lt;- hchart(penguins,\"scatter\", \n       hcaes(x = flipper_length_mm, y = bill_length_mm, group = species)) |&gt;\n  # x axis label\n  hc_xAxis(title = list(text = \"Flipper Length (mm)\")) |&gt;\n  # y axis label\n  hc_yAxis(title = list(text = \"Bill Length (mm)\")) |&gt;\n  # title and subtitle\n  hc_title(text = \"Gentoo's have &lt;i&gt;big&lt;/i&gt; flippers!\",\n           margin = 20, # space between title (or subtitle) and plot [default = 15]\n           align = \"left\",\n           stlyle = list(useHTML = TRUE)) |&gt;\n  hc_subtitle(text = \"A scatter graph showing the relationship between flipper length \n              and bill length, for Adelie, Chinstrap and Gentoo penguins\",\n              align = \"left\") |&gt;\n  # a source\n hc_credits(\n    text = \"Chart created using R and highcharter\",\n    href = \"http://jkunst.com/highcharter\",\n    enabled = TRUE\n    ) |&gt;\n  # hover box options\n  hc_tooltip(\n    headerFormat = \"&lt;b&gt;{series.name}&lt;/b&gt;&lt;br&gt;\",\n    pointFormat = \"Flipper Length: {point.x} mm&lt;br&gt;Bill Length: {point.y} mm\"\n    #&gt; valueSuffix applies globally but only when values are displayed individually\n    #&gt; here, displayed twice so hard-coded into 'pointFormat'\n    #&gt;valueSuffix = \" mm\"\n  ) |&gt;\n  hc_colors(c(\"#12436D\", \"#28A197\", \"#801650\"))\n  \nhc_penguins"
  },
  {
    "objectID": "posts/01-highcharter/index.html#adding-accessibility",
    "href": "posts/01-highcharter/index.html#adding-accessibility",
    "title": "Getting Started with Accessible Highcharter",
    "section": "Adding accessibility",
    "text": "Adding accessibility\nHere we assume the visually aspects of the graph are accessible.3 In this section I will add the following capabilities to the graph.\n3 This is probably a big assumption. I am assuming the following information given by the Government Analysis Function (which apply to static charts) has been applied:\n\nGuidance on designing charts.\nGuidance on the use of colour. For alternative colour palettes, consider Paul Tol’s notes\n\n\nThe ability to download the data;\nKeyboard navigation;\nAlt text, following guidance given by Amy Cesal in her blog post, “Writing Alt Text for Data Visualization”.\n\n\nExporting the data\nFirst, lets try and include a menu to export the data and the plot as an image – this requires using a module. Examples of using modules and plug-ins4 in {highcharter} are given in the modules vignette.\n4 I’m not sure what the difference is between a ‘module’ and a ‘plug-in’, except that the ‘.js’ files seem to live in different folders.\n\nCode\nhc_penguins2 &lt;- hc_penguins |&gt;\n  #hc_add_dependency(name = \"modules/exporting.js\") |&gt; \n  #hc_add_dependency(name = \"modules/export-data.js\") |&gt; \n  hc_exporting(\n    enabled = TRUE,\n    filename = \"palmer_penguins\"\n  )\n\nhc_penguins2\n\n\n\n\n\n\n\n\n\n\n\n\nComment on hc_add_dependency\n\n\n\nIn the quartoandme blog, the following lines are included in the ‘working example’:\n  hc_add_dependency(name = \"modules/accessibility.js\") |&gt; \n  hc_add_dependency(name = \"modules/exporting.js\") |&gt; \n  hc_exporting(\n    enabled = TRUE\n  )\nBut, (I think) the hc_exporting() function automatically includes the exporting.js and export-data.js modules when enabled = TRUE, so the two hc_add_dependency calls are unnecessary. I’m willing to be proved wrong here.\n\n\n\n\nKeyboard navigation\nTo get keyboard navigation working, we need to use the accessibility Highchart module.\n\n\n\n\n\n\nRequired changes to {highcharter} v0.9.4\n\n\n\nIf using v0.9.4 of {highcharter}, then copying the code below will result in no plot being output. This is a known issue, and is discussed in the GitHub repo issue 755.\nThere are two ways to fix this issue:\n\nUncomment the accessibility module in the ‘highcharts.yaml’ file.5 On my Mac, this is found at /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/library/highcharter/htmlwidgets (for your computer, use .libPaths() to find the default path for packages). The line\n\n    # - modules/accessibility.js\n    needs to be edited to be\n    - modules/accessibility.js\n    before loading the package into R.\n\nInstall an older version of {highcharter}, for example,6\n\nremotes::install_github(\"jbkunst/highcharter@8ff41366c8c411b497b5378d27be48617360f81f\")\n\n\n6 taken from mfherman’s reply to GitHub issue 755.5 Discussed by batpigandme in their reply to GitHub issue 755.\n\nCode\nhc_penguins3 &lt;- hc_penguins |&gt;\n  #hc_add_dependency(name = \"modules/exporting.js\") |&gt; \n  #hc_add_dependency(name = \"modules/export-data.js\") |&gt; \n  hc_add_dependency(name = \"modules/accessibility.js\") |&gt; \n  hc_exporting(\n    accessibility = list(\n      enabled = TRUE # default value is TRUE\n      ),\n    enabled = TRUE,\n    filename = \"palmer_penguins\"\n  ) |&gt;\n  hc_plotOptions(\n    accessibility = list(\n      enabled = TRUE,\n      keyboardNavigation = list(enabled = TRUE)\n      )\n    )\n\nhc_penguins3\n\n\n\n\n\n\n\n\nAlt text\n\n\n\n\n\nExample alt-text format for data viz, from Amy Cesal’s Medium post\n\n\nIn this section we add alt-text to the plot, to allow those using screen readers to understand the plot. )\nFirst, lets add accessible descriptions to the plot, by enabling the accessibility options in hc_xAxis and hc_yAxis.\n\n\nCode\nhc_penguins4 &lt;- hchart(penguins,\"scatter\", \n       hcaes(x = flipper_length_mm, y = bill_length_mm, group = species)) |&gt;\n  hc_add_dependency(name = \"modules/accessibility.js\") |&gt; \n  # x axis label\n  hc_xAxis(title = list(text = \"Flipper Length (mm)\"),\n           accessibility = list(\n                   enabled = TRUE,\n                   description = \"flipper length in millimeters\"\n           )) |&gt;\n  # y axis label\n  hc_yAxis(title = list(text = \"Bill Length (mm)\"),\n           accessibility = list(\n                   enabled = TRUE,\n                   description = \"bill length in millimeters\"\n           )) |&gt;\n  # title and subtitle\n  hc_title(text = \"Gentoo's have &lt;i&gt;big&lt;/i&gt; flippers!\",\n           margin = 20, # space between title (or subtitle) and plot [default = 15]\n           align = \"left\",\n           stlyle = list(useHTML = TRUE)) |&gt;\n  hc_subtitle(text = \"A scatter graph showing the relationship between flipper length \n              and bill length, for Adelie, Chinstrap and Gentoo penguins\",\n              align = \"left\") |&gt;\n  # a source\n hc_credits(\n    text = \"Chart created using R and highcharter\",\n    href = \"http://jkunst.com/highcharter\",\n    enabled = TRUE\n    ) |&gt;\n  # hover box options\n  hc_tooltip(\n    headerFormat = \"&lt;b&gt;{series.name}&lt;/b&gt;&lt;br&gt;\",\n    pointFormat = \"Flipper Length: {point.x} mm&lt;br&gt;Bill Length: {point.y} mm\"\n    #&gt; valueSuffix applies globally but only when values are displayed individually\n    #&gt; here, displayed twice so hard-coded into 'pointFormat'\n    #&gt;valueSuffix = \" mm\"\n  ) |&gt;\n  hc_colors(c(\"#12436D\", \"#28A197\", \"#801650\")) |&gt;\n  hc_exporting(\n    accessibility = list(\n      enabled = TRUE # default value is TRUE\n      ),\n    enabled = TRUE,\n    filename = \"palmer_penguins\"\n  ) |&gt;\n  hc_plotOptions(\n    accessibility = list(\n      enabled = TRUE,\n      keyboardNavigation = list(enabled = TRUE)\n      )\n    )\n  \nhc_penguins4\n\n\n\n\n\n\nNote that the desciption in hc_xAxis and hc_yAxis does not start with a capital letter. The reason why is clear from looking at the html output below. Here, aria-hidden=\"false\" refers to Accessible Rich Internet Applications, and is telling screen readers not to ignore this section.\n&lt;div id=\"highcharts-screen-reader-region-before-4\"\naria-label=\"Chart screen reader information, Gentoo's have big flippers!.\"\nstyle=\"position: relative;\" role=\"region\" aria-hidden=\"false\"&gt;\n...\n&lt;h4&gt;Gentoo's have big flippers!&lt;/h4&gt;\n&lt;div&gt;Scatter chart with 3 data series.&lt;/div&gt;\n...\n&lt;div&gt;The chart has 1 X axis displaying flipper length in millimeters. Range: 171.41 to 231.59.&lt;/div&gt;\n&lt;div&gt;The chart has 1 Y axis displaying bill length in millimeters. Range: 30 to 65.&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;\nThe alt-text is saved as a string to the alt_text_penguins object.\n\n\nCode\nalt_text_penguins &lt;- \"A scatter plot displays the relationship between bill\n        length (mm) on the y-axis and flipper length (mm) on the x-axis for\n        three penguin species: Adelie, Chinstrap, and Gentoo. Each species is\n        represented by a different colour: dark blue for Adelie, teal for Chinstrap,\n        and burgundy for Gentoo. Gentoo penguins have the largest flipper and bill\n        lengths, forming a distinct cluster towards the upper right of the graph.\n        Adelie penguins have smaller flipper and bill lengths, clustering at the lower\n        left, while Chinstrap penguins are positioned between the other two species.\n        The chart highlights that Gentoo penguins have notably large flippers.\"\n\n\n\nUsing Highchart accessibility description\nThe simple way to include this alt-text in the plot would be to use the hc_chart() function with the accessibility.description option set to equal alt_text_penguins. But, as discussed in the Highcharts accessibility documentation,\n\nNote: Since Highcharts now supports captions and linked descriptions, it is preferred to define the description using those methods, as a visible caption/description benefits all users. If the accessibility.description option is defined, the linked description is ignored, and the caption is hidden from screen reader users.\n\n\n\nCode\nhc_penguins4 |&gt;\n  hc_chart(\n    accessibility = list(\n      description = alt_text_penguins\n    )\n  )\n\n\n\n\n\n\n\n\nUsing linkedDescription\nHere, we first define an external HTML element, where the &lt;div&gt; with an ID (chart-description) contains the description of the chart. Then, then the linkedDescription option in hc_chart(accessibility = ...) connects the chart to the &lt;div&gt; by its ID.\n\n\nIf accessibility.description is also defined in the chart, it will override the linked description, as mentioned in the documentation.\n\n\nCode\n# Add an external description for the chart\ndescription_id &lt;- \"chart-description\"\n\ncat(sprintf(\n  '&lt;div id=\"%s\"&gt;\n    A scatter plot displays the relationship between bill length (mm) on the y-axis \n    and flipper length (mm) on the x-axis for three penguin species: Adelie, Chinstrap, \n    and Gentoo. Each species is represented by a different colour: dark blue for Adelie, \n    teal for Chinstrap, and burgundy for Gentoo. Gentoo penguins have the largest flipper \n    and bill lengths, forming a distinct cluster towards the upper right of the graph. \n    Adelie penguins have smaller flipper and bill lengths, clustering at the lower left, \n    while Chinstrap penguins are positioned between the other two species. \n    The chart highlights that Gentoo penguins have notably large flippers.\n  &lt;/div&gt;',\n  description_id\n))\n\n\n&lt;div id=\"chart-description\"&gt;\n    A scatter plot displays the relationship between bill length (mm) on the y-axis \n    and flipper length (mm) on the x-axis for three penguin species: Adelie, Chinstrap, \n    and Gentoo. Each species is represented by a different colour: dark blue for Adelie, \n    teal for Chinstrap, and burgundy for Gentoo. Gentoo penguins have the largest flipper \n    and bill lengths, forming a distinct cluster towards the upper right of the graph. \n    Adelie penguins have smaller flipper and bill lengths, clustering at the lower left, \n    while Chinstrap penguins are positioned between the other two species. \n    The chart highlights that Gentoo penguins have notably large flippers.\n  &lt;/div&gt;\n\n\n\n\nCode\nhc_penguins4 |&gt;\n  hc_chart(\n    accessibility = list(\n      linkedDescription = description_id\n    )\n  )"
  },
  {
    "objectID": "posts/01-highcharter/index.html#finished",
    "href": "posts/01-highcharter/index.html#finished",
    "title": "Getting Started with Accessible Highcharter",
    "section": "Finished",
    "text": "Finished\nWhat have we achieved here? I think we have some good looking graphs, which contain some accessibility features to increase integration with screen-readers. The {highcharter} package seems relatively easy to use, even though the syntax is a little different to what I’m used to (from base R and {ggplot2}).\nWe have:\n\nAdded \\(x\\) and \\(y\\) axis labels, and used these labels in the hover box text.\nAdded a title, subtitle, and a source.\nChanged the colours of the points.\nAllowed for exporting of the data, via hc_exporting().\nAllowed for keyboard navigation, including in the drop-down menu, using hc_add_dependency().\nAdded alt-text, via both description and linkedDescription options.\n\nThe next time I look at Highcharts and {highcharter}, I will be creating different graphs to see what capabilities Highcharts has, and whether it could be useful in my work."
  },
  {
    "objectID": "posts/05-mlr3_basic_modelling/index.html",
    "href": "posts/05-mlr3_basic_modelling/index.html",
    "title": "Getting Started with {mlr3}",
    "section": "",
    "text": "I am attempting to learn how to use {mlr3} (Lang et al. 2019), by reading through the book Applied Machine Learning Using mlr3 in R (Bischl et al. 2024).\n\nLang, Michel, Martin Binder, Jakob Richter, Patrick Schratz, Florian Pfisterer, Stefan Coors, Quay Au, Giuseppe Casalicchio, Lars Kotthoff, and Bernd Bischl. 2019. “mlr3: A Modern Object-Oriented Machine Learning Framework in R.” Journal of Open Source Software, December. https://doi.org/10.21105/joss.01903.\n\nBischl, Bernd, Raphael Sonabend, Lars Kotthoff, and Michel Lang, eds. 2024. Applied Machine Learning Using mlr3 in R. CRC Press. https://mlr3book.mlr-org.com.\n\nFoss, Natalie, and Lars Kotthoff. 2024. “Data and Basic Modeling.” In Applied Machine Learning Using mlr3 in R, edited by Bernd Bischl, Raphael Sonabend, Lars Kotthoff, and Michel Lang. CRC Press. https://mlr3book.mlr-org.com/data_and_basic_modeling.html.\nIn this first blog post, I am going through the exercises given in Section 2 (Foss and Kotthoff 2024). This involves creating a classification tree model, on the PimaIndiansDiabetes2 (from the {mlbench} package), to predict whether a person has diabetes or not. No (proper) evaluation or validation is done here – that’ll be for a later post.\n\n\n\nlibrary(mlr3)\nlibrary(mlr3viz)\nlibrary(ggplot2)\nlibrary(patchwork)\nlibrary(data.table)\noptions(datatable.print.nrows = 20)"
  },
  {
    "objectID": "posts/05-mlr3_basic_modelling/index.html#prerequisites",
    "href": "posts/05-mlr3_basic_modelling/index.html#prerequisites",
    "title": "Getting Started with {mlr3}",
    "section": "",
    "text": "library(mlr3)\nlibrary(mlr3viz)\nlibrary(ggplot2)\nlibrary(patchwork)\nlibrary(data.table)\noptions(datatable.print.nrows = 20)"
  },
  {
    "objectID": "posts/05-mlr3_basic_modelling/index.html#sec-question-one",
    "href": "posts/05-mlr3_basic_modelling/index.html#sec-question-one",
    "title": "Getting Started with {mlr3}",
    "section": "Question 1",
    "text": "Question 1\nTrain a classification model with the \"classif.rpart\" learner on the Pima Indians Diabetes dataset. Do this without using tsk(\"pima\"), and instead by constructing a task from the dataset in the mlbench package: data(PimaIndiansDiabetes2, package = \"mlbench\").\n\n\n\n\n\n\nMissing data\n\n\n\n\n\nNote: The dataset has NAs in its features. You can either rely on rpart’s capability to handle them internally (surrogate splits) or remove them from the initial data.frame using na.omit().\nThe rpart algorithm has a built-in method called surrogate splits, which allows it to handle missing values without removing data. If a feature value is missing at a particular split, rpart:\n\nTries to use an alternative feature (a surrogate variable) that closely mimics the main splitting feature.\nIf no good surrogate is found, it assigns the most common class (for classification) or the mean value (for regression) within that split.\n\n\n\n\n\nMake sure to define the pos outcome as the positive class.\nTrain the model on a random 80% subset of the given data and evaluate its performance with the classification error measure on the remaining data.\n\n\nAnswer\nLoading the data:\n\ndata(PimaIndiansDiabetes2, package = \"mlbench\")\npima &lt;- as.data.table(PimaIndiansDiabetes2)\npima\n\n     pregnant glucose pressure triceps insulin  mass pedigree   age diabetes\n        &lt;num&gt;   &lt;num&gt;    &lt;num&gt;   &lt;num&gt;   &lt;num&gt; &lt;num&gt;    &lt;num&gt; &lt;num&gt;   &lt;fctr&gt;\n  1:        6     148       72      35      NA  33.6    0.627    50      pos\n  2:        1      85       66      29      NA  26.6    0.351    31      neg\n  3:        8     183       64      NA      NA  23.3    0.672    32      pos\n  4:        1      89       66      23      94  28.1    0.167    21      neg\n  5:        0     137       40      35     168  43.1    2.288    33      pos\n ---                                                                        \n764:       10     101       76      48     180  32.9    0.171    63      neg\n765:        2     122       70      27      NA  36.8    0.340    27      neg\n766:        5     121       72      23     112  26.2    0.245    30      neg\n767:        1     126       60      NA      NA  30.1    0.349    47      pos\n768:        1      93       70      31      NA  30.4    0.315    23      neg\n\n\nI want to predict whether each person has diabetes, using a CART (‘classification and regression tree’).\n\nCreating a task\nFirst, I create the task. I am defining pos to be the positive class in this step. It can also be done later by setting tsk_pima$positive = \"pos\".\n\ntsk_pima &lt;- as_task_classif(pima, target = \"diabetes\", positive = \"pos\")\ntsk_pima\n\n&lt;TaskClassif:pima&gt; (768 x 9)\n* Target: diabetes\n* Properties: twoclass\n* Features (8):\n  - dbl (8): age, glucose, insulin, mass, pedigree, pregnant, pressure,\n    triceps\n\n\n\n#autoplot(tsk_pima, type = \"duo\") +\n  #theme(strip.text.y = element_text(angle = -0, size = 8))\n\nautoplot(tsk_pima, type = \"pairs\")\n\n\n\n\n\n\n\nFigure 1: A pairs plot of the pima dataset. Note that it is unbalanced, as there are more negative diabetes outcomes than positive.\n\n\n\n\n\nLet’s see how unbalanced the data is…\n\npima[, .N, by = \"diabetes\"]\n\n   diabetes     N\n     &lt;fctr&gt; &lt;int&gt;\n1:      pos   268\n2:      neg   500\n\n\n\n\nSplitting the data\nCreate a split of \\(80\\%\\) training and \\(20\\%\\) test data.\n\n\n\n\n\n\nImportant\n\n\n\nI know this is bad practice. Most of the time (see below for caveats), all the data should be used to fit the model, and then internal validation done via resampling (e.g. using bootstrap or cross-validation).\nFrom Frank Harrell’s blog,\n\ndata splitting is an unstable method for validating models or classifiers, especially when the number of subjects is less than about 20,000 (fewer if signal:noise ratio is high). This is because were you to split the data again, develop a new model on the training sample, and test it on the holdout sample, the results are likely to vary significantly. Data splitting requires a significantly larger sample size than resampling to work acceptably well\n\nAlso see Steyerberg (2018).\nTo chose whether to do internal or external validation, see the Biostatistics for Biomedical Research summary.\n\n\n\nSteyerberg, Ewout W. 2018. “Validation in Prediction Research: The Waste by Data Splitting.” Journal of Clinical Epidemiology 103: 131–33.\n\nset.seed(52)\nsplits &lt;- partition(tsk_pima, ratio = 0.8)\nsplits\n\n$train\n  [1]   1   2   3   4   5   8   9  10  11  12  14  18  19  20  21  22  23  24\n [19]  25  27  28  29  30  31  32  34  35  36  37  38  39  40  41  42  43  44\n [37]  46  48  49  50  51  52  53  54  55  56  57  58  59  60  61  62  63  64\n [55]  65  66  69  70  71  72  77  78  79  80  81  82  83  85  86  88  89  90\n [73]  91  92  93  94  97  98  99 100 101 103 104 105 106 107 108 109 110 111\n [91] 112 113 114 116 117 118 119 120 121 122 123 124 125 128 129 130 132 133\n[109] 135 136 137 138 139 140 142 143 144 145 146 148 149 151 152 153 157 158\n[127] 159 160 161 162 163 164 165 166 167 169 170 171 173 174 175 177 178 179\n[145] 180 181 182 183 184 185 186 187 188 189 190 191 194 195 196 197 198 199\n[163] 200 201 202 203 204 205 206 207 209 210 212 213 215 216 217 218 220 221\n[181] 222 224 225 226 228 229 231 233 234 235 236 237 238 243 244 245 246 247\n[199] 248 251 252 255 256 257 258 259 261 262 263 264 266 267 268 269 270 271\n[217] 273 275 276 277 279 280 281 282 283 284 285 286 287 290 291 292 293 294\n[235] 295 297 298 299 301 302 305 306 307 309 310 311 312 313 314 315 316 318\n[253] 319 320 321 322 324 326 327 328 329 330 331 332 333 334 335 336 337 339\n[271] 340 341 343 344 346 347 349 350 351 352 353 354 355 356 357 358 359 360\n[289] 361 364 365 366 367 368 369 370 371 372 373 374 375 376 378 379 380 381\n[307] 382 384 386 387 389 390 391 392 393 394 395 396 397 398 399 401 402 403\n[325] 404 405 406 407 408 409 410 411 412 414 415 416 417 418 420 421 422 423\n[343] 424 425 427 429 430 433 436 437 439 440 441 442 443 444 445 446 447 448\n[361] 449 450 451 452 453 454 455 456 457 459 461 463 464 465 466 469 470 471\n[379] 472 473 474 476 477 478 482 483 484 485 486 487 488 489 490 491 493 494\n[397] 495 497 498 499 500 501 503 504 505 506 508 509 510 511 512 513 514 515\n[415] 516 517 518 520 521 522 523 524 526 527 528 529 530 532 533 534 535 536\n[433] 537 538 539 542 543 544 545 548 549 550 551 552 553 554 555 556 557 560\n[451] 562 563 564 565 566 568 569 570 572 573 574 575 576 578 579 580 581 582\n[469] 583 584 585 586 588 589 590 591 592 594 595 596 597 598 600 601 602 603\n[487] 604 605 606 607 608 609 610 611 612 615 616 617 618 619 620 621 623 625\n[505] 627 628 629 630 632 634 635 636 637 639 640 641 642 643 644 645 646 647\n[523] 649 650 651 654 656 658 659 660 661 662 663 665 666 667 669 670 672 674\n[541] 676 677 678 681 683 684 686 687 688 689 690 692 693 695 697 698 700 701\n[559] 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 722 723\n[577] 724 725 726 727 728 729 730 732 735 736 737 738 739 740 741 742 743 744\n[595] 746 748 749 750 751 752 753 754 756 757 758 759 760 761 762 763 764 765\n[613] 766 767\n\n$test\n  [1]   6   7  13  15  16  17  26  33  45  47  67  68  73  74  75  76  84  87\n [19]  95  96 102 115 126 127 131 134 141 147 150 154 155 156 168 172 176 192\n [37] 193 208 211 214 219 223 227 230 232 239 240 241 242 249 250 253 254 260\n [55] 265 272 274 278 288 289 296 300 303 304 308 317 323 325 338 342 345 348\n [73] 362 363 377 383 385 388 400 413 419 426 428 431 432 434 435 438 458 460\n [91] 462 467 468 475 479 480 481 492 496 502 507 519 525 531 540 541 546 547\n[109] 558 559 561 567 571 577 587 593 599 613 614 622 624 626 631 633 638 648\n[127] 652 653 655 657 664 668 671 673 675 679 680 682 685 691 694 696 699 718\n[145] 719 720 721 731 733 734 745 747 755 768\n\n$validation\ninteger(0)\n\n\n\n\nTraining the model\nNow, I will train the classification tree on the training data.\n\n# loading the learners\nlrn_featureless &lt;- lrn(\"classif.featureless\", predict_type = \"prob\")\nlrn_rpart &lt;- lrn(\"classif.rpart\", predict_type = \"prob\") # 'prob' is the default prediction type\nlrn_rpart\n\n&lt;LearnerClassifRpart:classif.rpart&gt;: Classification Tree\n* Model: -\n* Parameters: xval=0\n* Packages: mlr3, rpart\n* Predict Types:  response, [prob]\n* Feature Types: logical, integer, numeric, factor, ordered\n* Properties: importance, missings, multiclass, selected_features,\n  twoclass, weights\n\n# training the learners\nlrn_featureless$train(tsk_pima, splits$train)\nlrn_rpart$train(tsk_pima, splits$train)\nlrn_rpart\n\n&lt;LearnerClassifRpart:classif.rpart&gt;: Classification Tree\n* Model: rpart\n* Parameters: xval=0\n* Packages: mlr3, rpart\n* Predict Types:  response, [prob]\n* Feature Types: logical, integer, numeric, factor, ordered\n* Properties: importance, missings, multiclass, selected_features,\n  twoclass, weights\n\n\n\n\nEvaluating the model\nHere, I’m evaluating the model on the test data (and comparing against the featureless learner).\nI will consider the Brier, log-loss and accuracy measures. The Brier score lies between \\([0,\n1]\\), where \\(0\\) is best. The log-loss is the negative logarithm of the predicted probability for the true class, and the accuracy is the number of correct predictions divided by total number of predictions.\n\n# load accuracy measures\nmeasures = msrs(c(\"classif.mbrier\", \"classif.logloss\", \"classif.acc\"))\n\n# predicting using the featureless learner\nprediction_featureless &lt;- lrn_featureless$predict(tsk_pima, splits$test)\nprediction_featureless \n\n&lt;PredictionClassif&gt; for 154 observations:\n row_ids truth response  prob.pos  prob.neg\n       6   neg      neg 0.3485342 0.6514658\n       7   pos      neg 0.3485342 0.6514658\n      13   neg      neg 0.3485342 0.6514658\n     ---   ---      ---       ---       ---\n     747   pos      neg 0.3485342 0.6514658\n     755   pos      neg 0.3485342 0.6514658\n     768   neg      neg 0.3485342 0.6514658\n\n\n\n# obtaining score of featureless learner\nprediction_featureless$score(measures)\n\n classif.mbrier classif.logloss     classif.acc \n      0.4553977       0.6478575       0.6493506 \n\n\n\n# predicting using the classification tree\nprediction_rpart &lt;- lrn_rpart$predict(tsk_pima, splits$test)\nprediction_rpart \n\n&lt;PredictionClassif&gt; for 154 observations:\n row_ids truth response   prob.pos  prob.neg\n       6   neg      neg 0.00000000 1.0000000\n       7   pos      neg 0.08675799 0.9132420\n      13   neg      neg 0.24390244 0.7560976\n     ---   ---      ---        ---       ---\n     747   pos      pos 0.77777778 0.2222222\n     755   pos      pos 0.76744186 0.2325581\n     768   neg      neg 0.08675799 0.9132420\n\n\n\n# obtaining score of the classification tree\nprediction_rpart$score(measures) \n\n classif.mbrier classif.logloss     classif.acc \n      0.2763229       0.8516860       0.8246753 \n\n\n\n# confusion matrix\n1prediction_rpart$confusion\n\n\n1\n\nAll off-diagonal entries are incorrectly classified observations, and all diagonal entries are correctly classified.\n\n\n\n\n        truth\nresponse pos neg\n     pos  40  13\n     neg  14  87\n\n\n\nprediction_plot &lt;- autoplot(prediction_rpart) + ggtitle(\"Default\")\nprediction_plot"
  },
  {
    "objectID": "posts/05-mlr3_basic_modelling/index.html#question-2",
    "href": "posts/05-mlr3_basic_modelling/index.html#question-2",
    "title": "Getting Started with {mlr3}",
    "section": "Question 2",
    "text": "Question 2\nCalculate the true positive, false positive, true negative, and false negative rates of the predictions made by the model in Exercise 1.\n\nTry to solve this in two ways:\n\nUsing mlr3measures-predefined measure objects.\nWithout using mlr3 tools by directly working on the ground truth and prediction vectors.\n\nCompare the results.\n\n\nAnswer\nI’ve already started this in Question 1 (Section 2.1.1.4), but I will reiterate here. The confusion matrix gives the number of predictions that are correct (true positives or negatives) on the diagonal, and those that are incorrect (false positives and negatives) on the top right and bottom left, respectively\n\n# confusion matrix\nconf_matrix &lt;- prediction_rpart$confusion\nconf_matrix\n\n        truth\nresponse pos neg\n     pos  40  13\n     neg  14  87\n\n\nI want to obtain the rates, both using the mlr3measures objects, and without.\n\n\n\nSensitivity\n\n(true positive rate) is the probability of a positive test result, conditioned on the individual truly being positive.\n\nSpecificity\n\n(true negative rate) is the probability of a negative test result, conditioned on the individual truly being negative.\n\n\n\nUsing mlr3measures\nFirst, let’s figure out the measures we need…\n\nas.data.table(mlr_measures)[task_type == \"classif\" & predict_type == \"response\"]\n\nKey: &lt;key&gt;\n                    key                         label task_type\n                 &lt;char&gt;                        &lt;char&gt;    &lt;char&gt;\n 1:         classif.acc       Classification Accuracy   classif\n 2:        classif.bacc             Balanced Accuracy   classif\n 3:          classif.ce          Classification Error   classif\n 4:       classif.costs Cost-sensitive Classification   classif\n 5:         classif.dor         Diagnostic Odds Ratio   classif\n---                                                            \n19: classif.specificity                   Specificity   classif\n20:          classif.tn                True Negatives   classif\n21:         classif.tnr            True Negative Rate   classif\n22:          classif.tp                True Positives   classif\n23:         classif.tpr            True Positive Rate   classif\n             packages predict_type properties task_properties\n               &lt;list&gt;       &lt;char&gt;     &lt;list&gt;          &lt;list&gt;\n 1: mlr3,mlr3measures     response                           \n 2: mlr3,mlr3measures     response                           \n 3: mlr3,mlr3measures     response                           \n 4:              mlr3     response                           \n 5: mlr3,mlr3measures     response                   twoclass\n---                                                          \n19: mlr3,mlr3measures     response                   twoclass\n20: mlr3,mlr3measures     response                   twoclass\n21: mlr3,mlr3measures     response                   twoclass\n22: mlr3,mlr3measures     response                   twoclass\n23: mlr3,mlr3measures     response                   twoclass\n\n\nOK, so we need to use the measures classif.tpr classif.fpr classif.tnr and classif.fnr, for the true positive, false positive, true negative and false negative rates, respectively.\n\nmeasures &lt;- msrs(c(\"classif.tpr\", \"classif.fpr\", \"classif.tnr\", \"classif.fnr\"))\nprediction_rpart$score(measures)\n\nclassif.tpr classif.fpr classif.tnr classif.fnr \n  0.7407407   0.1300000   0.8700000   0.2592593 \n\n\n\n\nWithout using mlr3measures\nI can obtain these rates directly from the confusion matrix.\n\nstr(conf_matrix)\n\n 'table' int [1:2, 1:2] 40 14 13 87\n - attr(*, \"dimnames\")=List of 2\n  ..$ response: chr [1:2] \"pos\" \"neg\"\n  ..$ truth   : chr [1:2] \"pos\" \"neg\"\n\n# true positive rate / sensitivity\ntpr &lt;- conf_matrix[1, 1]/ sum(conf_matrix[, 1])\n# false positive rate\nfpr &lt;- conf_matrix[1, 2]/ sum(conf_matrix[, 2])\n\n# true negative rate / specificity\ntnr &lt;- conf_matrix[2, 2]/ sum(conf_matrix[, 2])\n# false negative rate\nfnr &lt;- conf_matrix[2, 1]/ sum(conf_matrix[, 1])\n\ndata.table(\n  classif.tpr = tpr,\n  classif.fpr = fpr,\n  classif.tnr = tnr,\n  classif.fnr = fnr\n)\n\n   classif.tpr classif.fpr classif.tnr classif.fnr\n         &lt;num&gt;       &lt;num&gt;       &lt;num&gt;       &lt;num&gt;\n1:   0.7407407        0.13        0.87   0.2592593"
  },
  {
    "objectID": "posts/05-mlr3_basic_modelling/index.html#question-3",
    "href": "posts/05-mlr3_basic_modelling/index.html#question-3",
    "title": "Getting Started with {mlr3}",
    "section": "Question 3",
    "text": "Question 3\nChange the threshold of the model from Question 1 such that the false positive rate is lower than the false negative rate.\n\nWhat is one reason you might do this in practice?\n\n\nAnswer\nOne reason I might want a lower false positive rate than false negative rate is it the damage done by a false positive is higher than that done by a false negative. That if, if classifying the outcome as positive when it is actually negative is more damaging than the other way round. For example, if I am building a model to predict fraud for a bank, and a false positive would result in a customer transaction being wrongly declined. Lots of false positives could result in annoyed customers and a loss of trust.\n\nInverse weights\nLet’s first change the thresholds such that they account for the inbalanced data. I’m not considering false positives here.\nFrom Figure 1, it’s clear that the data is unbalanced (more people with negative diabetes than positive). I can account for this by changing the thresholds using inverse weightings.\nFirst, let’s use the training data to obtain new thresholds.\n\nnew_thresh = proportions(table(tsk_pima$truth(splits$train)))\nnew_thresh\n\n\n      pos       neg \n0.3485342 0.6514658 \n\n\nAnd then I’ll use these thresholds to reweight the model.\n\nprediction_rpart$set_threshold(new_thresh)\nprediction_rpart$confusion\n\n        truth\nresponse pos neg\n     pos  40  13\n     neg  14  87\n\nprediction_plot_newt &lt;- autoplot(prediction_rpart) +\n                                ggtitle(\"Inverse weighting thresholds\")\nprediction_plot + prediction_plot_newt +\n        plot_layout(guides = \"collect\")\n\n\n\n\n\n\n\n\nOh, it doesn’t make a difference!\n\n\nReducing false positive rate\nThis can be achieved by making it more difficult for the model to predict a positive result.\nSo, let’s create thresholds where the pos result is penalised.\n\nnew_thresh &lt;- c(\"pos\" = 0.7, \"neg\" = 0.3)\n\n\nprediction_rpart$set_threshold(new_thresh)\nprediction_rpart$confusion\n\n        truth\nresponse pos neg\n     pos  35  10\n     neg  19  90\n\nmeasures &lt;- msrs(c(\"classif.tpr\", \"classif.fpr\", \"classif.tnr\", \"classif.fnr\"))\nprediction_rpart$score(measures)\n\nclassif.tpr classif.fpr classif.tnr classif.fnr \n  0.6481481   0.1000000   0.9000000   0.3518519 \n\nprediction_plot_newt &lt;- autoplot(prediction_rpart) +\n                                ggtitle(\"New thresholds\")\nprediction_plot + prediction_plot_newt +\n        plot_layout(guides = \"collect\")\n\n\n\n\n\n\n\n\nHere, the false positive rate has decreased, but the false negative has increased (as expected)."
  },
  {
    "objectID": "posts/06-stepwise_datasplitting/index.html",
    "href": "posts/06-stepwise_datasplitting/index.html",
    "title": "Model Fitting and Validation",
    "section": "",
    "text": "This post is partly a expansion of a comment I made about training/test sets in a previous post. At work, we often need to fit a model and validate it (using internal validation), in the presence of missing data. This short article ignores the missing data issue (I will look at this later), but instead focuses on fitting and validating a model.\nThere are two main areas that I am looking at here, to try and improve current practice:\n\nFitting a model\nValidating the chosen model\n\nThis short article collates some of the critiques in the way we currently do model building and validation.\n\n\nCurrently, at work we use a stepwise procedure to chose explanatory variables in the model. This stepwise procedure is sometimes a mix of clinical judgement with some form of automated selection, and sometimes it is fully automated. This is often done on a test set which consists of around \\(70\\%\\) of the full data. The remaining \\(30\\%\\) of the data is used for model validation.1\n1 For an example of a fully automated stepwise procedure on a \\(70\\%\\) training set, with validation on the remaining \\(30\\%\\) test set, see Collett, Friend, and Watson (2017).\nCollett, David, Peter J Friend, and Christopher JE Watson. 2017. “Factors Associated with Short-and Long-Term Liver Graft Survival in the United Kingdom: Development of a UK Donor Liver Index.” Transplantation 101 (4): 786–92.\nThere are lots of issues that result from this process: from the use of the stepwise procedure, and from not using all the data to fit the model (data-splitting)."
  },
  {
    "objectID": "posts/06-stepwise_datasplitting/index.html#current-practice",
    "href": "posts/06-stepwise_datasplitting/index.html#current-practice",
    "title": "Model Fitting and Validation",
    "section": "",
    "text": "Currently, at work we use a stepwise procedure to chose explanatory variables in the model. This stepwise procedure is sometimes a mix of clinical judgement with some form of automated selection, and sometimes it is fully automated. This is often done on a test set which consists of around \\(70\\%\\) of the full data. The remaining \\(30\\%\\) of the data is used for model validation.1\n1 For an example of a fully automated stepwise procedure on a \\(70\\%\\) training set, with validation on the remaining \\(30\\%\\) test set, see Collett, Friend, and Watson (2017).\nCollett, David, Peter J Friend, and Christopher JE Watson. 2017. “Factors Associated with Short-and Long-Term Liver Graft Survival in the United Kingdom: Development of a UK Donor Liver Index.” Transplantation 101 (4): 786–92.\nThere are lots of issues that result from this process: from the use of the stepwise procedure, and from not using all the data to fit the model (data-splitting)."
  }
]